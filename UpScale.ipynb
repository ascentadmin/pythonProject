{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ascentadmin/pythonProject/blob/master/UpScale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wa3lqWEzMeR",
        "outputId": "52cf33db-9335-45f0-cfee-cdf3706e9612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive successfully mounted.\n",
            "Collecting pygit2==1.12.2\n",
            "  Downloading pygit2-1.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pygit2==1.12.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.21)\n",
            "Installing collected packages: pygit2\n",
            "Successfully installed pygit2-1.12.2\n",
            "/content/drive/MyDrive/Github\n",
            "fatal: destination path 'Fooocus' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Github/Fooocus\n",
            "Already up to date.\n",
            "How Many SDXL Checkpoints Would You Like To Download (Maximum 4): 0\n",
            "How Many Lora Files Would You Like To Download: 0\n",
            "/content/drive/MyDrive/Github/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.2.0\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/launch.py\", line 127, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/webui.py\", line 10, in <module>\n",
            "    import modules.async_worker as worker\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/modules/async_worker.py\", line 2, in <module>\n",
            "    from modules.patch import PatchSettings, patch_settings, patch_all\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/modules/patch.py\", line 5, in <module>\n",
            "    import ldm_patched.modules.model_base\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/modules/model_base.py\", line 2, in <module>\n",
            "    from ldm_patched.ldm.modules.diffusionmodules.openaimodel import UNetModel, Timestep\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 15, in <module>\n",
            "    from ..attention import SpatialTransformer, SpatialVideoTransformer, default\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/ldm/modules/attention.py\", line 9, in <module>\n",
            "    from .sub_quadratic_attention import efficient_dot_product_attention\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/ldm/modules/sub_quadratic_attention.py\", line 27, in <module>\n",
            "    from ldm_patched.modules import model_management\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/modules/model_management.py\", line 121, in <module>\n",
            "    total_vram = get_total_memory(get_torch_device()) / (1024 * 1024)\n",
            "  File \"/content/drive/MyDrive/Github/Fooocus/ldm_patched/modules/model_management.py\", line 90, in get_torch_device\n",
            "    return torch.device(torch.cuda.current_device())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 769, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Install modules for downloading our SDXL models\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check TensorFlow GPU availability\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is GPU available? \", tf.test.is_gpu_available())\n",
        "\n",
        "# List available GPUs\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "def mount_gdrive():\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"Google Drive successfully mounted.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while mounting Google Drive: {e}\")\n",
        "\n",
        "def download_file_from_url(url, folder_path, user_filename):\n",
        "    try:\n",
        "        # Full path to save the file\n",
        "        save_path = os.path.join(folder_path, user_filename)\n",
        "\n",
        "        # Send a GET request to the URL\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "\n",
        "        # Get the total file size\n",
        "        file_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # Create a progress bar\n",
        "        progress_bar = tqdm(total=file_size, unit='iB', unit_scale=True)\n",
        "\n",
        "        # Open the file to write the content\n",
        "        with open(save_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                progress_bar.update(len(chunk))\n",
        "                file.write(chunk)\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        # Check if the file size is correct\n",
        "        if file_size != 0 and file_size != progress_bar.n:\n",
        "            print(\"ERROR: Something went wrong with the download. Please try again.\")\n",
        "        else:\n",
        "            print(f\"File downloaded successfully to {save_path}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred while downloading the file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "def collect_download_info(num_models, num_lora_files):\n",
        "    # Collect download information for SDXL models\n",
        "    model_download_info = []\n",
        "    for i in range(num_models):\n",
        "        url = input(f\"Paste SDXL Checkpoint URL #{i + 1} Here: \")\n",
        "        user_filename = input(f\"Enter the filename for Checkpoint #{i + 1} (including .ckpt or .safetensors extension): \")\n",
        "        model_download_info.append((url, user_filename))\n",
        "\n",
        "    # Collect download information for Lora files\n",
        "    lora_download_info = []\n",
        "    for i in range(num_lora_files):\n",
        "        lora_url = input(f\"Paste Lora File URL #{i + 1} Here: \")\n",
        "        lora_name = input(f\"Enter the filename for Lora File #{i + 1} (including .safetensors extension): \")\n",
        "        lora_download_info.append((lora_url, lora_name))\n",
        "\n",
        "    return model_download_info, lora_download_info\n",
        "\n",
        "# Mount GDrive\n",
        "mount_gdrive()\n",
        "\n",
        "# Use pip to install pygit\n",
        "!pip install pygit2==1.12.2\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/Github'):\n",
        "  os.makedirs('/content/drive/MyDrive/Github')\n",
        "\n",
        "# Change Directory\n",
        "%cd /content/drive/MyDrive/Github\n",
        "\n",
        "# Clone the Fooocus repo\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "\n",
        "# Change Directory\n",
        "%cd /content/drive/MyDrive/Github/Fooocus\n",
        "\n",
        "# Make sure we are running larest version if already installed\n",
        "!git pull\n",
        "\n",
        "# Ask the user how many models and Lora files they want to download\n",
        "num_models = int(input(\"How Many SDXL Checkpoints Would You Like To Download (Maximum 4): \"))\n",
        "if num_models > 4:\n",
        "    print(\"Maximum allowed is 4.\")\n",
        "    num_models = 4\n",
        "\n",
        "num_lora_files = int(input(\"How Many Lora Files Would You Like To Download: \"))\n",
        "\n",
        "# Collect download information for SDXL models and Lora files\n",
        "model_download_info, lora_download_info = collect_download_info(num_models, num_lora_files)\n",
        "\n",
        "# Specify the folder path where you want to save the checkpoint files\n",
        "checkpoint_folder_path = \"/content/drive/MyDrive/Github/Fooocus/models/checkpoints\"\n",
        "\n",
        "# Download all requested SDXL checkpoint files\n",
        "for url, user_filename in model_download_info:\n",
        "    download_file_from_url(url, checkpoint_folder_path, user_filename)\n",
        "\n",
        "# Specify the folder path where you want to save the Lora files\n",
        "lora_folder_path = \"/content/drive/MyDrive/Github/Fooocus/models/loras\"\n",
        "\n",
        "# Download all requested Lora files\n",
        "for lora_url, lora_name in lora_download_info:\n",
        "    download_file_from_url(lora_url, lora_folder_path, lora_name)\n",
        "\n",
        "# Define the new output folder path\n",
        "new_output_folder = '/content/drive/MyDrive/Images/Fooocus'\n",
        "\n",
        "# Check if the new output folder exists, and create it if it doesn't\n",
        "if not os.path.exists(new_output_folder):\n",
        "    os.makedirs(new_output_folder)\n",
        "    print(f\"Created the new output folder: {new_output_folder}\")\n",
        "\n",
        "# Define the symbolic link path\n",
        "symbolic_link_path = '/content/drive/MyDrive/Github/Fooocus/outputs'\n",
        "\n",
        "# Check if the symbolic link exists, and create it if it doesn't\n",
        "if not os.path.exists(symbolic_link_path):\n",
        "    os.symlink(new_output_folder, symbolic_link_path)\n",
        "    print(f\"Created the symbolic link to the new output folder.\")\n",
        "\n",
        "# Start Fooocus and check for updates\n",
        "%cd /content/drive/MyDrive/Github/Fooocus/\n",
        "!python entry_with_update.py --share\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNkFRENhV3lI1Ddr87rnsjj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}